/home/d310/anaconda3/envs/oiqa_rjl/lib/python3.9/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Traceback (most recent call last):
  File "/home/d310/10t/rjl/TMM_OIQA/code/OIQAND_train.py", line 111, in <module>
    loss_val, plcc, srcc, rmse = train_oiqand(net, criterion, optimizer, train_loader)
  File "/home/d310/10t/rjl/TMM_OIQA/code/OIQAND_load_train.py", line 50, in train_oiqand
    pred_d = net(d)     # [B]
  File "/home/d310/anaconda3/envs/oiqa_rjl/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/d310/anaconda3/envs/oiqa_rjl/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 168, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/home/d310/anaconda3/envs/oiqa_rjl/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 178, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/home/d310/anaconda3/envs/oiqa_rjl/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py", line 86, in parallel_apply
    output.reraise()
  File "/home/d310/anaconda3/envs/oiqa_rjl/lib/python3.9/site-packages/torch/_utils.py", line 457, in reraise
    raise exception
RuntimeError: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/home/d310/anaconda3/envs/oiqa_rjl/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/home/d310/anaconda3/envs/oiqa_rjl/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/d310/10t/rjl/TMM_OIQA/code/OIQAND_model.py", line 234, in forward
    x = self.VPQP(x)
  File "/home/d310/anaconda3/envs/oiqa_rjl/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/d310/10t/rjl/TMM_OIQA/code/OIQAND_model.py", line 197, in forward
    seq = self.ma(seq)
  File "/home/d310/anaconda3/envs/oiqa_rjl/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/d310/10t/rjl/TMM_OIQA/code/OIQAND_model.py", line 90, in forward
    attn = self.softmax(attn)
  File "/home/d310/anaconda3/envs/oiqa_rjl/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/d310/anaconda3/envs/oiqa_rjl/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1261, in forward
    return F.softmax(input, self.dim, _stacklevel=5)
  File "/home/d310/anaconda3/envs/oiqa_rjl/lib/python3.9/site-packages/torch/nn/functional.py", line 1818, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 3.66 GiB (GPU 0; 23.69 GiB total capacity; 9.42 GiB already allocated; 2.30 GiB free; 12.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

